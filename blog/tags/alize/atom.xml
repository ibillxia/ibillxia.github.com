<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: Alize | Bill's Blog]]></title>
  <link href="http://ibillxia.github.io/blog/tags/alize/atom.xml" rel="self"/>
  <link href="http://ibillxia.github.io/"/>
  <updated>2024-10-08T22:34:18+08:00</updated>
  <id>http://ibillxia.github.io/</id>
  <author>
    <name><![CDATA[Bill Xia]]></name>
    <email><![CDATA[ibillxia@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[使用Alize等工具构建说话人识别平台]]></title>
    <link href="http://ibillxia.github.io/blog/2013/04/26/building-speaker-recognition-system-using-alize-etc/"/>
    <updated>2013-04-26T22:07:00+08:00</updated>
    <id>http://ibillxia.github.io/blog/2013/04/26/building-speaker-recognition-system-using-alize-etc</id>
    <content type="html"><![CDATA[<p>前段时间有好几位同学询问如何用Alize实现说话人识别的问题，由于寒假前赶Paper，来不及详细解答，更没时间写Demo。
开学后不久抽时间写了一个Demo，并上传到了GitHub：<a href="https://github.com/ibillxia/VoicePrintReco/tree/master/Demo">VoicePrintReco-branch-master</a>. 现在新版的 Alize 3.0 已经提供了更多的官方 demo，我也将 GitHub 的源码升级了 <a href="https://github.com/ibillxia/VoicePrintReco">VPR2.0</a>， 其中的Demos文件夹有Alize官方的4个demo和我自己写的这个demo。</p>

<h3>基本流程</h3>

<p>下面将利用Alize+SPro进行简单的GMM-Based的说话人识别的基本流程总结如下：</p>

<h4>1.Features extraction 特征提取</h4>

<p>sfbcep.exe（MFCC）或slpcep.exe（LPCC）</p>

<h4>2.Silence removal 静音检测和去除</h4>

<p>NormFeat.exe 先能量规整<br/>
EnergyDetector.exe 基于能量检测的静音去除</p>

<h4>3.Features Normalization 特征规整</h4>

<p>NormFeat.exe 再使用这个工具进行特征规整</br></p>

<h4>4.World model training</h4>

<p>TrainWorld.exe 训练UBM</br></p>

<h4>5.Target model training</h4>

<p>TrainTarget.exe 在训练好UBM的基础上训练training set的GMM</br></p>

<h4>6.Testing</h4>

<p>ComputeTest.exe 将testing set在training set的GMM上进行测试和打分</br></p>

<h4>7.Score Normalization</h4>

<p>ComputeNorm.exe 将得分进行规整</br></p>

<h4>8. Compute EER 计算等错误率</h4>

<p>你可以查查计算EER的matlab代码，NIST SRE的官网上有下载<a href="http://www.itl.nist.gov/iad/mig//tools/DETware_v2.1.targz.htm">DETware_v2.1.tar.gz</a> 。_</p>

<!-- more -->


<h3>获取帮助</h3>

<p>关于各步骤中参数的问题，可以在命令行“工具 -help”来查看该工具个参数的具体含义，另外还可参考Alize源码中各个工具的test目录中提供的实例，
而关于每个工具的作用及理论知识则需要查看相关论文。</p>

<p>常见问题及解答: <a href="http://mistral.univ-avignon.fr/mediawiki/index.php/Frequently_asked_questions">Frequently asked questions - by alize</a></p>

<p>更多问题请在 <a href="https://groups.google.com/forum/?fromgroups=&amp;hl=zh-CN#!forum/alize---voice-print-recognition">Google Groups</a> 提出，大家一起讨论！</p>

<p>另外，还可以通过 QQ 群：二⑦九⑥四④零⑤柒 进行Real-Time的交流与讨论，加群请注明学校姓名，以防广告。</p>

<h3>推荐资料</h3>

<p>[1] ALIZE - User Manual: <a href="http://mistral.univ-avignon.fr/doc/userguide_alize.001.pdf">userguide_alize.001.pdf</a><br/>
[2] LIA_SPKDET Package documentation: <a href="http://mistral.univ-avignon.fr/doc/userguide_LIA_SpkDet.002.pdf">userguide_LIA_SpkDet.002.pdf</a><br/>
[3] <a href="http://www-clips.imag.fr/geod/User/laurent.besacier/NEW-TPs/TP-Biometrie/tools/CommentsLBInstall/doc.pdf">Reference System based on speech modality ALIZE/LIA RAL</a><br/>
[4] Jean-Francois Bonastre, etc. ALIZE/SpkDet: a state-of-the-art open source software for speaker recognition<br/>
[5] TOMMIE GANNERT. A Speaker Veri?cation System Under The Scope: Alize<br/>
[6] <a href="http://mistral.univ-avignon.fr/mediawiki/index.php/Main_Page">Alize Wiki</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GMM-SVM-NAP Method in Speaker Recognition]]></title>
    <link href="http://ibillxia.github.io/blog/2012/08/13/GMM-SVM-NAP-Method-in-Speaker-Recognition/"/>
    <updated>2012-08-13T22:38:00+08:00</updated>
    <id>http://ibillxia.github.io/blog/2012/08/13/GMM-SVM-NAP-Method-in-Speaker-Recognition</id>
    <content type="html"><![CDATA[<h2>1.Gaussian Mixture Models(GMM)</h2>


<p>For a D-dimensional feature vector, x, the mixture density used for the likelihood function is deﬁned as</br>
<center>$p(x|\lambda) = \sum_{i=1}^{M}w_{i}p_{i}(x)$.</center></br>
The density is a weighted linear combination of $M$ unimodal Gaussian densities , $p_{i}(x)$</br>
<center>$p_{i}(x) = \frac{1}{(2\pi)^{D/2}|\sum _{i}|^{1/2}} exp[-\frac{1}{2}(x-\mu_{i})^{T}(\sum _{i})^{-1}(x-\mu_{i})]$.</center></br>
</p>




<h2>2.Support Vector Machines(SVM)</h2>


<p>An SVM is a two-class classifier constructed from sums of a kernel function $K(• , •)$</br>
<center>$f(x) = \sum_{i=1}{N}\alpha_{i} t_{i} K(x,x_{i}) + d$.</center></br>
$t_{i}$ are the ideal outputs,  $\sum_{i=1}{N}\alpha_{i} t_{i}=0$ and $\alpha_{i} > 0$,$x_{i}$ are support vectors and obtained 
from the training set by an optimization process.</br>
$K(. , .)$ is constrained to have certain properties (the Mercer condition), so that it can be expressed as</br>
<center>$K(x,y) = b(x)^{T} b(y)$.</center></br>
Kernel function examples: <a href="http://www.shamoxia.com/html/y2010/2292.html">http://www.shamoxia.com/html/y2010/2292.html</a>
</p>




<!-- more -->


<h2>3.GMM-SVM</h2>


<p>GMM Supervectors：given a speaker utterance, GMM-UBM training is performed by MAP adaptation of the means $m_{i}$, 
and we form a GMM supervector $m = [m_{i}]$</br>
<img src="/images/2012/IMAG2012081301.jpg"></br>
GMM Supervectors Linear Kernel: a natural distance between the two utterances is the KL divergence, while it does n't satisfy 
the Mercer condition, we consider the following approximation</br>
<center>$\begin{align}
D(g_{a}\parallel g_{b}) = &\int_{R^{n}}g_{a}xlog\left(\frac{g_{a}(x)}{g_{b}(x)} \right)dx \\
\leq & \sum_{i=1}^{N} \lambda _{i}D(N(.;m_{i}^{a},\Sigma _{i})\parallel N(.;m_{i}^{b},\Sigma _{i}))\\
= &\frac{1}{2}\sum_{i=1}^{N}\lambda_{i}(m_{i}^{a}-m_{i}^{b})\Sigma ^{-1}(m_{i}^{a}-m_{i}^{b})
\end{align}$</center></br>
we can define a new distance formula,</br>
<center>$d(m^{a},m^{b}) = \frac{1}{2} \sum_{i=1}^{N}\lambda_{i}(m_{i}^{a}-m_{i}^{b})\Sigma_{i}^{-1}(m_{i}^{a}-m_{i}^{b})$</center></br>
From the distance, we can find the corresponding inner product which is the kernel function.
</p>




<h2>4.SVM-NAP</h2>


<p>Nuisance Attribute Projection(NAP) attempts to remove the unwanted within-class variation of the observed feature vectors. 
This is achieved by applying the transform</br>
<center>$y' = P_{n}y = (I-V_{n}V_{n}^{T})y$.</center></br>
where Vn is the principal directions of within-class variability.
</p>




<p>The SVM NAP constructs a new kernel,
<center>$\begin{align}
K(m^{a},m^{b}) =& [Pb(m^{a})]^{T}[Pb(m^{b})]\\
=& b(m^{a})^{t}Pb(m^{b})\\
=& b(m^{a})^{t}(I-vv^{t})b(m^{b})
\end{align}$.</center></br>
where $P$ is a projection ($P^{2} = P$) , $v$ is the direction being removed from the SVM expansion 
space. $b(.)$ is the SVM expansion, and $\parallel v\parallel ^{2} = 1$.
</p>




<h2>5.Experiments on NIST SRE 2010</h2>


<p>In the experiments, I use the spro4 to extract MFCC and LPCC features, and use Alize to 
build GMM-UBM and all of the remained tasks.</p>




<h2>References</h2>


<p>
[1]Douglas A. Reynolds, T. F. Quatieri, and R. Dunn, Speaker verication using adapted Gaussian mixture models, Digital Signal Processing, vol. 10, no. 1-3, pp. 1941, 2000.</br>
[2]W. Campbell, “Generalized linear discriminant sequence kernels for speaker recognition,” in IEEE International Conference on Acoustics, Speech, and Signal Processing, vol. 1, 2002, pp. 161–164.</br>
[3]W. M. Campbell, D. E. Sturim, D. A. Reynolds, A. Solomonoff, SVM Based Speaker Verification Using a GMM Supervector Kernel and NAP Variability Compensation.</br>
[4]Robbie Vogt, Sachin Kajarekar, Sridha Sridharan, Discriminant NAP for SVM Speaker Recognition.
</p>

]]></content>
  </entry>
  
</feed>