
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Bill's Blog</title>
  <meta name="author" content="Bill Xia">

  
  <meta name="description" content="Yesterday is History, Tomorrow a Mystery, Today is a Gift, Thats why it's called the Present！">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://ibillxia.github.io/page5">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/bootstrap/bootstrap.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/bootstrap/responsive.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/syntax/syntax.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/style.css" media="screen, projection" rel="stylesheet" type="text/css">
  <style type="text/css">
    body {
      padding-bottom: 0px;
    }
    h1 {
      margin-bottom: 15px;
    }
    img {
      max-width: 100%;
    }
    .sharing, .meta, .pager {
      margin: 20px 0px 20px 0px;
    }
    .page-footer p {
      text-align: center;
    }
  </style>
  <script src="/javascripts/libs/jquery.js"></script>
  <script src="/javascripts/libs/modernizr-2.0.js"></script>
  <script src="/javascripts/libs/bootstrap.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-34DJ0T23LB"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-34DJ0T23LB');
  </script>
  <link href="/atom.xml" rel="alternate" title="Bill's Blog" type="application/atom+xml">
  <script type="text/javascript">
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}

$(document).bind('DOMNodeInserted', function(event) {
  addBlankTargetForLinks();
});
</script>
<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'G-34DJ0T23LB']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>



  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5786957483481554" crossorigin="anonymous"></script>
</head>

<body   >
  <nav role="navigation"><div class="navbar navbar-inverse">
  <div class="navbar-inner">
    <div class="container">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>

      <a class="brand" href="/">Bill's Blog</a>

      <div class="nav-collapse">
        <ul class="nav">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/categories">Categories</a></li>
  <li><a href="/blog/tags">Tags</a></li>
  <li><a href="/about">About</a></li>
</ul>


        <ul class="nav pull-right" data-subscription="rss">
          <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
          
        </ul>

        
          <form class="pull-right navbar-search" action="http://www.google.com/" method="get">
            <fieldset role="search">
              <input type="hidden" name="q" value="site:ibillxia.github.io" />
              <input class="search-query" type="text" name="q" results="0" placeholder="Search"/>
            </fieldset>
          </form>
        
      </div>
    </div>
  </div>
</div>
</nav>
  <div class="container">
    <div class="row-fluid">
      <div class="span9">
  
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/06/04/a-simple-code-for-wave-recording-using-windows-api/">用Windows API实现一个简单的录音程序</a></h1>
    
    
      <p class="meta">
        









<time datetime="2013-06-04T23:59:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2013/06/04/a-simple-code-for-wave-recording-using-windows-api/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>本文介绍如何使用Windows API来录制语音信号兵保存到wave文件中，主要用到三个结构体和几个wave开头的API函数（在Winmm.lib文件中）。其中三个结构体是WAVEFORMATEX、WAVEHDR、MMTIME，其详细定义都在MMSystem.h中定义，
可以转到定义看其详细内容及每一项的英文注释。用到的API函数的详细用法可以参见MSDN： http://msdn.microsoft.com/en-us/library/windows/desktop/dd743847(v=vs.85).aspx
详细的使用过程请看下文的源代码，这是一个Win32 Application，需要手动添加Winmm.lib的依赖。</p>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/06/04/a-simple-code-for-wave-recording-using-windows-api/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/29/audio-signal-processing-time-domain-pitch-tracking-and-python-realization/">语音信号处理之时域分析-音高追踪及其Python实现</a></h1>
    
    
      <p class="meta">
        









<time datetime="2013-05-29T21:37:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2013/05/29/audio-signal-processing-time-domain-pitch-tracking-and-python-realization/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>1.概述</h2>


<p>在<a href="http://ibillxia.github.io/blog/2013/05/16/audio-signal-processing-time-domain-pitch-python-realization/">音高及其Python实现</a>一文
中，我们使用了简单的“观察法”来计算音高，这并不太难，但这并不有好而且费时费力，那么我们就想，如何通过分析和计算，使用算法来自动计算音高呢？
用算法让计算机自动抓取音高的过程，称为<b>音高追踪</b>(Pitch Tracking)。所得到的音高信息有如下一些应用：</br>
·旋律识别(Melody Recognition)：或称为“哼唱选歌”，也就是如何由使用者的哼唱，找出音乐资料库中间对应的歌。</br>
·汉语声调识别(Tone Recognition)：辨识使用者讲一句话时，每一个字的声调（一声、二声、三声、四声等）。</br>
·语音合成韵律分析(Prosody Analysis)中的音高分析：如何在合成语音时，使用最自然的音高曲线。</br>
·语音评分中的音调评分(Intonation Assessment)：如何评估使用者说话的语音，其音高曲线是否标准。</br>
·语音识别(Speech Recognition)：我们可以使用语句的音高来提高语音辨识的正确率。</br>
总而言之，音高追踪是语音信号处理中最基本也最重要的一个环节之一。
</p>




<h2>2.音高追踪的基本流程</h2>


<p>音高追踪的基本流程如下：</br>
(1)将整段音讯讯号切成音框（Frames），相邻音框之间可以重叠。</br>
(2)算出每个音框所对应的音高。</br>
(3)排除不稳定的音高值。（可由音量来筛选，或由音高值的范围来过滤。）</br>
(4)对整段音高进行平滑化，通常是使用「中位数滤波器」（Median Filters）。</br>
</p>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/29/audio-signal-processing-time-domain-pitch-tracking-and-python-realization/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/24/cctv-news-rat-understand-what-human-says/">大白鼠听人话</a></h1>
    
    
      <p class="meta">
        









<time datetime="2013-05-24T22:59:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2013/05/24/cctv-news-rat-understand-what-human-says/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>最近一直忙着准备给媒体展示的音控大鼠机器人一不小心上了CCTV了，虽然自己感觉没什么了不起的，也不知道网络上是什么评论。
但既然上了CCTV，还是发博纪念一下吧</p>




<p>央视新闻视频链接：<a href="http://tv.cntv.cn/vodplay/e58c8785e00a4ead9b83dfae5b53f12a/860010-1102010100">浙江杭州最新科研成果：大白鼠听人话</a>
真没想到自己居然正面出境这么长时间。</p>




<p>杭州日报的记者写的新闻还挺生动的：<a href="http://hzdaily.hangzhou.com.cn/hzrb/html/2013-05/24/content_1501396.htm">“嫁接”了机器视觉的大白鼠在沙盘迷宫中寻觅阿汤哥的照片</a></p>




<p>PS：感谢CCTV，感谢杭州日报，感谢ZJU，感谢CCNT，感谢各位老师和同学，感谢生仪的给大鼠做开颅手术的两位mm，感谢各位在微博帮忙宣传和转发的各位同学！</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/22/audio-signal-processing-time-domain-Voice-Activity-Detection/">语音信号处理之时域分析-端点检测及Python实现</a></h1>
    
    
      <p class="meta">
        









<time datetime="2013-05-22T22:22:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2013/05/22/audio-signal-processing-time-domain-Voice-Activity-Detection/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>端点检测</h2>


<p>端点检测（End-Point Detection，EPD）的目标是要决定信号的语音开始和结束的位置，所以又可以称为Speech Detection或Voice Activity Detection（VAD）。
端点检测在语音预处理中扮演着一个非常重要的角色。</p>




<p>常见的端点检测方法大致可以分为如下两类：</br>
（1）时域（Time Domain）的方法：计算量比较小，因此比较容易移植到计算能力较差的嵌入式平台</br>
（a）音量：只使用音量来进行端检，是最简单的方法，但是容易对清音造成误判。另外，不同的音量计算方法得到的结果也不尽相同，至于那种方法更好也没有定论。</br>
（b）音量和过零率：以音量为主，过零率为辅，可以对清音进行较精密的检测。</br>
（2）频域（Frequency Domain）的方法：计算量相对较大。</br>
（a）频谱的变化性（Variance）：有声音的频谱变化较规律，可以作为一个判断标准。</br>
（b）频谱的Entropy：有规律的频谱的Entropy一般较小，这也可以作为一个端检的判断标准。
</p>




<p>下面我们分别从这两个方面来探讨端检的具体方法和过程。</p>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/22/audio-signal-processing-time-domain-Voice-Activity-Detection/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/18/audio-signal-processing-time-domain-timbre-python-realization/">语音信号处理之时域分析-音色及其Python实现</a></h1>
    
    
      <p class="meta">
        









<time datetime="2013-05-18T21:57:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2013/05/18/audio-signal-processing-time-domain-timbre-python-realization/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>音色（Timbre）</h2>


<p>音色是一个很模糊的概念，它泛指语音的内容，例如“天书”这两个字的发音，虽然都是一声（即他们的音高应该是相同或接近的），
但由于音色不同，我们可以分辨这两个音。直觉而言，音色的不同，意味着基本波形的不同，因此我们可以用基本周期的波形来代表音色。
</p>




<p>若要从基本周期的波形来直接分析音色是一件很困难的事情。通常我们的做法是将每一个帧进行频谱分析（Spectral Analysis），算出一个
帧如何分解为不同频率的分量，然后才能进行对比或分析。在频谱分析中，最常用的方法就是快速傅里叶变换（Fast Fourier Transform，FFT），
这是一个相当常用的方法，可以讲在时域（Time Domain）的信号转换成频域（Frequency Domain）的信号，并进而知道每个频率的信号强度。</p>




<p>语谱图（Spectrogram）就是语音频谱图，一般是通过处理接收的时域信号得到频谱图，因此只要有足够时间长度的时域信号就可以(时间长度
为保证频率分辨率)。专业点讲，语谱图就是频谱分析视图，如果针对语音数据的话，叫语谱图。语谱图的横坐标是时间，纵坐标是频率，坐标点
值为语音数据能量，因而语谱图很好的表达了语音的音色随时间变化的趋势。有些经验丰富的人能够通过看语谱图而知道对应的语音信号的内容，
这种技术成为Spectrogram Reading。</p>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/18/audio-signal-processing-time-domain-timbre-python-realization/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/16/audio-signal-processing-time-domain-pitch-python-realization/">语音信号处理之时域分析-音高及其Python实现</a></h1>
    
    
      <p class="meta">
        









<time datetime="2013-05-16T23:10:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2013/05/16/audio-signal-processing-time-domain-pitch-python-realization/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>音高（Pitch）</h2>


<p>概念：音高（Pitch）是语音信号的一个很重要的特征，直觉上而言它表示声音频率的高低，这个频率是指基本频率（基频），也即基本周期的倒数。
若直接观察语音的波形，只要语音信号稳定，我们可以很容易的看出基本周期的存在。例如我们取一个包含256个采样点的帧，单独绘制波形图，就可以明显的
看到它的基本周期。如下图所示：
<center><img src="/images/2013/IMAG2013051601.png"></center>
其中最上面的波形为|a|的发音，中间的为上图中红色双竖线（位于语音区）所对应的帧的具体波形，而最下面的是上图中绿色双竖线（位于静音区）所
对应的帧的具体波形。很容易看到中间的波形具有明显的周期性。
</p>


</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/16/audio-signal-processing-time-domain-pitch-python-realization/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/15/audio-signal-processing-time-domain-ZeroCR-python-realization/">语音信号处理之时域分析-过零率及其Python实现</a></h1>
    
    
      <p class="meta">
        









<time datetime="2013-05-15T21:44:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2013/05/15/audio-signal-processing-time-domain-ZeroCR-python-realization/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>过零率（Zero Crossing Rate）</h2>


<p>概念：过零率（Zero Crossing Rate，ZCR）是指在每帧中，语音信号通过零点（从正变为负或从负变为正）的次数。
这个特征已在语音识别和音乐信息检索领域得到广泛使用，是对敲击的声音的分类的关键特征。</p>




<p>ZCR的数学形式化定义为：
<center>$zcr = \frac{1}{T-1}\sum_{t=1}^{T-1}\pi\{s_{t}s_{t-1}<0\}$.</center>
其中$s$是采样点的值，$T$为帧长，函数$\pi\{A\}$在A为真是值为1，否则为0.
</p>




<p>特性：</br>
(1).一般而言，清音（unvoiced sound）和环境噪音的ZCR都大于浊音（voiced sound）；</br>
(2).由于清音和环境噪音的ZCR大小相近，因而不能够通过ZCR来区分它们；</br>
(3).在实际当中，过零率经常与短时能量特性相结合来进行端点检测，尤其是ZCR用来检测清音的起止点；</br>
(4).有时也可以用ZCR来进行粗略的基频估算，但这是非常不可靠的，除非有后续的修正（refine）处理过程。
</p>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/15/audio-signal-processing-time-domain-ZeroCR-python-realization/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/15/audio-signal-process-time-domain-volume-python-realization/">语音信号处理之时域分析-音量及其Python实现</a></h1>
    
    
      <p class="meta">
        









<time datetime="2013-05-15T19:36:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2013/05/15/audio-signal-process-time-domain-volume-python-realization/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>1.概述（Introduction）</h2>


<p>本系列文主要介绍语音信号时域的4个基本特征及其Python实现，这4个基本特征是：</br>
(1)音量（Volume）；</br>
(2)过零率（Zero-Crossing-Rate）；</br>
(3)音高（Pitch）；</br>
(4)音色（Timbre）。
</p>




<h2>2.音量（Volume）</h2>


<p>音量代表声音的强度，可由一个窗口或一帧内信号振幅的大小来衡量，一般有两种度量方法：</br>
（1）每个帧的振幅的绝对值的总和：
<center>$volume = \sum_{i=1}^{n}|s_{i}|$.</center>
其中$s_{i}$为第该帧的$i$个采样点，$n$为该帧总的采样点数。这种度量方法的计算量小，但不太符合人的听觉感受。</br>
（2）幅值平方和的常数对数的10倍：
<center>$volume = 10 * log_{10}\sum_{i=1}^{n}s_{i}^{2}$.</center>
它的单位是分贝（Decibels），是一个对数强度值，比较符合人耳对声音大小的感觉，但计算量稍复杂。
</p>


</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/15/audio-signal-process-time-domain-volume-python-realization/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/08/speech-processing-in-time-domain/">语音信号处理基础学习笔记之时域处理</a></h1>
    
    
      <p class="meta">
        









<time datetime="2013-05-08T23:13:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2013/05/08/speech-processing-in-time-domain/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>语音信号的分析分为时域、频域、倒谱域等，时域分析简单、运算量小、物理意义明确，但对于语音识别而言，
更为有效的是频域的分析方法，那么为什么还有进行时域的分析呢？</p>




<p>语音信号具有时变特性，但在短时内可以看做是平稳的，所以语音的时域分析是建立在“短时”的条件下的，经研究统计，
语音信号在帧长为10ms~30ms内是相对平稳的。</p>




<p>语音信号是模拟信号，在进行处理之前，要进行数字化，模拟信号数字化的一般方法是采样，按照Nyquist采样定理进行
采样（一般在8K~10KHz）后，在进行量化（一般用8bit，也有16bit等）和编码，变为数字信号。</p>




<p>在语音信号数字化之后，就可以开始对其进行处理了，首先是预处理，由于语音信号的平均功率谱受声门激励和口鼻辐射的影响，
高频端大约在800Hz以上按6dB/倍频程跌落，为此要在预处理中进行预加重。预加重的目的是提升高频部分，是信号变得平坦，
以便于进行频谱分析或声道参数分析。预加重可以用具有6dB/倍频程的提升高频特性的预加重数字滤波器实现。预处理的另一
方面工作是分帧和加窗：分帧的帧长一般在10ms~30ms，分帧既可以是连续的，也可以是有部分over-lap；短时分析的实质是
对信号加窗，一般采用Hamming窗，其他的还有矩形窗、汉宁窗等，如下图所示。
<center><img src="/images/2013/IMAG2013050801.png"></center>
</p>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/08/speech-processing-in-time-domain/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/01/go-hiking-International-Labour-Day/">五一登高远足</a></h1>
    
    
      <p class="meta">
        









<time datetime="2013-05-01T22:01:00+08:00" pubdate data-updated="true"></time>
        
         | <a href="/blog/2013/05/01/go-hiking-International-Labour-Day/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>五一天晴气爽，登高望远，强身健体！只可惜“不畏浮云遮望眼，只缘身在最高层” 这句诗在空气严重污染的今天已不适用了！</p>




<p><img src="/images/2013/IMAG2013050101.jpg">

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/01/go-hiking-International-Labour-Day/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  <ul class="pager">
    
    <li class="previous"><a href="/page6">&larr; Older</a></li>
    
    <li><a href="/blog/archives">Blog Archives</a></li>
    
    <li class="next"><a href="/page4">Newer &rarr;</a></li>
    
  </ul>
</div>
<aside class="sidebar-nav span3">
  
    
  
</aside>

    </div>
  </div>
  <footer role="contentinfo" class="page-footer">
<hr>
<p>
  Copyright &copy; 2009 - 2025 - <a href="http://about.me/ibillxia">Bill Xia</a> -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> - Theme by <a href="https://github.com/bkutil/bootstrap-theme">bootstrap-theme</a> </span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'ibillxia';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
